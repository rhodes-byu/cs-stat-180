{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rhodes-byu/cs-stat-180/blob/main/labs/08-clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><p><b>After clicking the \"Open in Colab\" link, copy the notebook to your own Google Drive before getting started, or it will not save your work</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most straightforward tasks we can perform on a data set without labels is to find groups of data in our dataset which are similar to one another -- what we call clusters.\n",
    "\n",
    "K-Means is one of the most popular \"clustering\" algorithms. K-means stores k centroids that it uses to define clusters. A point is considered to be in a particular cluster if it is closer to that cluster's centroid than any other centroid.\n",
    "\n",
    "K-Means finds the best centroids by alternating between (1) assigning data points to clusters based on the current centroids (2) chosing centroids (points which are the center of a cluster) based on the current assignment of data points to clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Dataset: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### MNIST dataset â€” a brief overview\n",
    "\n",
    "**Introduction**\n",
    "The MNIST (Modified National Institute of Standards and Technology) dataset is a widely used benchmark in machine learning. It contains images of handwritten digits and is often used to teach and test classification and clustering techniques.\n",
    "\n",
    "**Description**\n",
    "- Type: Handwritten digit images  \n",
    "- Size: 70,000 grayscale images (28 Ã— 28 pixels)  \n",
    "  - Training set: 60,000 images  \n",
    "  - Test set: 10,000 images  \n",
    "- Classes: 10 (digits 0â€“9)  \n",
    "- Format: Each example is a flattened 784-dimensional vector (28Ã—28 pixels) or a 28Ã—28 image with pixel values in [0, 255].  \n",
    "\n",
    "**Why use MNIST?**\n",
    "- It is commonly used as a 'toy' dataset in machine learning.\n",
    "- Simple and well-structured, so students can focus on methods rather than data cleaning.\n",
    "- Large enough to illustrate practical issues (scaling, dimensionality reduction, speed) but small enough to run on a laptop when sampled.\n",
    "\n",
    "**Accessing MNIST**\n",
    "Use scikit-learn's `fetch_openml` to download the MNIST dataset:\n",
    "\n",
    "```python\n",
    "        from sklearn.datasets import fetch_openml\n",
    "        mnist = fetch_openml('mnist_784', version=1, parser='auto')\n",
    "        X, y = mnist['data'], mnist['target']\n",
    "```\n",
    "\n",
    "Format returned by `fetch_openml('mnist_784')`:\n",
    "- `X`: a table-like object with 70,000 rows and 784 columns; each row is a flattened 28Ã—28 image (pixels ordered 0...783). Pixel values are typically in the range 0â€“255.  \n",
    "- `y`: labels for each row (digits 0â€“9), often returned as strings; convert to integers with `y = y.astype(int)` if desired.  \n",
    "  \n",
    "\n",
    "Quick note: to visualize a row as an image use: `X.iloc[i].values.reshape(28,28)` (or `X.values[i].reshape(28,28)`), then display with `plt.imshow(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "# Set global random seed for the notebook\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version = 1, parser = 'auto')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST digits in this set are flattened arrays of 784 pixels. We can reshape them to 28x28 pixels and plot them using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = X.iloc[0, :].values.reshape((28, 28))\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing the Data\n",
    "\n",
    "a. Using the full dataset, *normalize* each column so that the minimum column value is 0, and the maximum is 1. This is a standard practice for image datasets.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Get a random sample of 10% of the data. The full dataset may take a while to run some of the below methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fitting k-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Using the MNIST subset, determine the optimal k value for k-means according to the WCSS elbow method. Use a range of k-values from 2 - 15. (Hint: The plot will not be cut and dry like some of the class examples; just use your best judgement!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Fit a k-means model with the optimal k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. High-dimensional dataâ€”like MNIST digit images with 784 pixelsâ€”are hard to visualize.  \n",
    "**Dimensionality reduction** helps us find a lower-dimensional view that keeps important patterns.\n",
    "\n",
    "**Principal Component Analysis (PCA)** is a simple and fast method that finds directions of maximum variation in the data. By keeping only the top two directions, we can make a 2D version of our data thatâ€™s easy to plot.\n",
    "\n",
    "Use **PCA** to reduce the MNIST data to **2 dimensions** (`n_components=2`).  \n",
    "Then make a **scatterplot** of the 2D data and **color the points by their k-means cluster labels**. Use the Dark2 colormap to help distingish the colors. It will also be helpful to shrink the point size (e.g., s = 0.5).\n",
    "\n",
    "ðŸ“˜ **Hint:** Use [`sklearn.decomposition.PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Create two side-by-side scatterplots using the PCA representation (first two principal components) using plt.subplots. Color the first fig according to the true labels and the second according to k-means cluster labels. Be sure to include proper figure titles and a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Describe the fit. Does this align with your expectation? (Note: The specific color used for the clusters and labels will not align, but do you see some of the same patterns emerge?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Display the cluster centroids as images in a grid using subplots. What digits do they most resemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hierarchical Clustering\n",
    "Here you will be performing hierarchical clustering on a smaller data subset.\n",
    "\n",
    "Here you will be comparing linkage methods and metrics. Use the following linkage/metric combinations:\n",
    "\n",
    "| Linkage Method | Metrics              |\n",
    "|---------------|----------------------|\n",
    "| Ward         | Euclidean            |\n",
    "| Complete     | Euclidean, Cosine |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Get a subset of 10% of your original subset (you should have 700 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Fit hierarhiccal clustering with 10 clusters for each combination and store the silhouette scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. According to the silhouette scores, which combination is best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualizing Clustered Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Pick one of the cluster labels from your best models (k-means or HC). Select a random subset of 20 points belonging to that cluster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Using subplots (4 rows, 5 columns), plot the 20 digit images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Comment on the clustered points (e.g., do they look similar?, are the representing the same digit?, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
